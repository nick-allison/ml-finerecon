{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "\n",
      "Sanity Checking: 0it [00:00, ?it/s]\n",
      "Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [04:52<00:00, 292.72s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'zip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:704: UserWarning: You passed `Trainer(accelerator='cpu', precision=16)` but native AMP is not supported on CPU. Using `precision='bf16'` instead.\n",
      "  rank_zero_warn(\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name              | Type           | Params\n",
      "-----------------------------------------------------\n",
      "0 | cnn2d             | Cnn2d          | 2.0 M \n",
      "1 | fusion            | FeatureFusion  | 94    \n",
      "2 | cnn3d             | EfficientCnn3d | 5.2 K \n",
      "3 | cnn2d_pb          | MobileNet2d    | 1.9 M \n",
      "4 | point_feat_mlp    | Sequential     | 9.2 K \n",
      "5 | point_fusion      | FeatureFusion  | 94    \n",
      "6 | surface_predictor | Sequential     | 7.0 K \n",
      "7 | occ_predictor     | Sequential     | 545   \n",
      "-----------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.9 M     Total params\n",
      "15.661    Total estimated model params size (MB)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\main.py\", line 72, in <module>\n",
      "    trainer.fit(model, ckpt_path=args.ckpt)\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 579, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py\", line 38, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 621, in _fit_impl\n",
      "    self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1058, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1137, in _run_stage\n",
      "    self._run_train()\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1150, in _run_train\n",
      "    self._run_sanity_check()\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1222, in _run_sanity_check\n",
      "    val_loop.run()\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\.conda\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py\", line 206, in run\n",
      "    output = self.on_run_end()\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\.conda\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py\", line 184, in on_run_end\n",
      "    self._on_evaluation_epoch_end()\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\.conda\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py\", line 294, in _on_evaluation_epoch_end\n",
      "    self.trainer._call_lightning_module_hook(hook_name)\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1302, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\fine_recon.py\", line 593, in on_validation_epoch_end\n",
      "    loader = self.predict_dataloader(first_scan_only=True)\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\fine_recon.py\", line 1238, in predict_dataloader\n",
      "    _, _, test_scans = self.get_scans()\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\fine_recon.py\", line 1186, in get_scans\n",
      "    train_scans, val_scans, test_scans = data.get_scans(\n",
      "  File \"c:\\Users\\NickA\\OneDrive\\Documents\\IIT Fall 2024\\CS 512\\ml-finerecon\\data.py\", line 21, in get_scans\n",
      "    with open(os.path.join(dataset_dir, \"train.txt\"), \"r\") as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data\\\\train.txt'\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "!python main.py --config config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Training is not feasible on a personal computer; the model is fully functional though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
